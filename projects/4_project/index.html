<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Robot Learning | Yi Wang</title> <meta name="author" content="Yi Wang"> <meta name="description" content="Personal website of Yi Wang. "> <meta name="keywords" content="yi wang, robotics, CV"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://allenwangyi.github.io/projects/4_project/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yi </span>Wang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Robot Learning</h1> <p class="post-description"></p> </header> <article> <p><strong>PART 1：</strong> In this project, I developed and trained Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) to navigate a simulated 2D maze environment. Utilizing an agent-based model, the project integrated dynamics, control systems, and machine learning to enable autonomous navigation towards a designated goal. The task complexity was heightened by randomizing the spawn locations of both the agent and the goal, and by incorporating multiple obstacle maps. The machine learning models were trained using human-generated data, where an expert user provided demonstrations through keyboard controls. This research illustrates the intersection of neural networks and robotics for complex autonomous navigation tasks.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj4_fig1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj4_fig1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj4_fig1-1400.webp"></source> <img src="/assets/img/proj4_fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Within the order of 1e-4 of pose estimation results. </div> <p><a href="https://colab.research.google.com/drive/1q2pl2tTfpugU69dM3x13EcOwGa1bzrV_?usp=sharing" rel="external nofollow noopener" target="_blank"><strong>Colab code</strong></a>:https://colab.research.google.com/drive/1q2pl2tTfpugU69dM3x13EcOwGa1bzrV_?usp=sharing</p> <p><strong>PART 2：</strong> In this project project, I employed Deep Learning techniques to train a 3-link robotic arm (‘arm_student’) to mimic the behavior of another similar arm (‘arm_teacher’) operating under known forward dynamics. The objective was to enable the ‘arm_student’ to learn the ground-truth forward dynamics of ‘arm_teacher’, which encompassed understanding the state of the arm and the application of torques at the joints. The system was initialized with a 6x1-dimensional numpy array representing state and a 3x1-dimensional array representing action in torque. The project utilized a simulation time step of 0.01 seconds, and applied a constant torque to the first joint of both arms for experimental analysis. The model was optimized for starting in a hanging position for performance consistency. Overall, this project epitomizes the application of machine learning in understanding and replicating complex mechanical dynamics</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj4_fig2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj4_fig2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj4_fig2-1400.webp"></source> <img src="/assets/img/proj4_fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Within the order of 1e-4 of pose estimation results. </div> <p><a href="https://colab.research.google.com/drive1Gx5iswzb9uGuXg1q2kjMVEaHT90GSq9G#scrollTo=D1vjDH2fL9Tu" rel="external nofollow noopener" target="_blank"><strong>Colab code</strong></a>:https://colab.research.google.com/drive/1Gx5iswzb9uGuXg1q2kjMVEaHT90GSq9G#scrollTo=D1vjDH2fL9Tu</p> <p><strong>PART 3：</strong> In a continuation of previous work involving n-linked robotic arms, this project focused on leveraging neural networks for learning forward dynamics. Utilizing a provided ‘teacher dynamics’ model and controller, the task was to train a ‘student dynamics’ model to mimic the ground-truth behavior of the arm. The system architecture consisted of key Python classes to handle robot control and dynamics, including a flexible ‘Robot’ interface for setting and retrieving state and actions, as well as advancing the system through time steps. The state of each arm was represented as a 2n-dimensional vector, consisting of n joint positions [rad] and n joint velocities [rad/s], while the action was characterized by n torques [N-m] applied to n joints. This project not only integrated machine learning techniques with complex robotics systems but also allowed for modular extensions to arms with varying numbers of links <a href="https://colab.research.google.com/drive/1q2pl2tTfpugU69dM3x13EcOwGa1bzrV_?usp=sharing#scrollTo=tIoNAwGQpHfH" rel="external nofollow noopener" target="_blank"><strong>Colab code</strong></a>:https://colab.research.google.com/drive/1q2pl2tTfpugU69dM3x13EcOwGa1bzrV_?usp=sharing#scrollTo=tIoNAwGQpHfH</p> <p><strong>PART 4：</strong> In this project, I implement reinforcement learning (RL) algorithms for an n-linked robotic arm within a custom ‘ArmEnv’ environment. This environment encapsulated the arm dynamics and provided essential functions like ‘reset(…)’ and ‘step(…)’, conforming to the expected RL API. I dealt with the challenge of adapting a high-dimensional, continuous action space to work with a Discrete Q-Network (DQN) by implementing action space conversions. The observation vector was extended to include both the end-effector position and goal, enabling the policy to learn to achieve arbitrary goals. Training and testing were carried out under a fixed episode length of 200 steps, with a time simulation of 0.01 seconds per step. The reward function was designed as the negative square of the L2 distance between the end-effector and the target position, optimizing the arm’s movements towards set objectives. <a href="https://colab.research.google.com/drive/1Y_WJglf208-H6yAFFn_phU49dpY23-kM?usp=sharing#scrollTo=t-JvzRuwNsYz" rel="external nofollow noopener" target="_blank"><strong>Colab code</strong></a>:https://colab.research.google.com/drive/1Y_WJglf208-H6yAFFn_phU49dpY23-kM?usp=sharing#scrollTo=t-JvzRuwNsYz</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yi Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>